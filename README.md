
## 🔍 Overview :
Hierarchical clustering builds a hierarchy of clusters represented by a dendrogram.
This project uses the Agglomerative (bottom-up) approach, where each data point starts in its own cluster, and pairs of clusters are merged based on proximity.

🛠️ Key Concepts
Agglomerative Clustering: Merges clusters iteratively based on shortest distance.

Ward's Method: Linkage criteria that minimizes within-cluster variance.

Dendrogram: A tree-like diagram to determine the optimal number of clusters.

## 📦 Libraries Used
-scikit-learn

-matplotlib

-pandas

-numpy

-scipy.cluster.hierarchy
## output:
dendogram

![image](https://github.com/SharmaShivani12/HC_implementation-/assets/116270548/82f2bc65-c6e6-4239-9b82-a3786e7e78b9)

Cluster:

![image](https://github.com/SharmaShivani12/HC_implementation-/assets/116270548/c4d387c4-85e6-4218-82bd-fbf6fb9556c8)

🙌 Credit / Shoutout
This project is inspired by the Machine Learning A-Z™: AI, Python & R course on Udemy. Huge thanks to the instructors for making complex concepts easy to understand!
